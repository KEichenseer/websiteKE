---
title: 'A Metropolis algorithm in R - Part 2: Adaptive proposals'
author: ''
date: '2022-03-26'
slug: a-metropolis-algorithm-in-r-part-2-adaptive-proposals
categories: []
tags: []
subtitle: ''
authors: []
lastmod: '2022-03-26T20:13:04Z'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
header-includes: \usepackage{graphics}
summary: The Metropolis algorithm is a simple, but powerful MCMC method. Here, I use it for estimating a generalised logistic function to reconstruct a latitudinal climate gradient from a small sample of temperature estimates.
---

<style>
.math {
  font-size: small;
}
</style>


<style type="text/css">
body, td {
   font-size: 14px;
}
code.r{
  font-size: 12px;
}
pre {
  font-size: 13.2px
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
> *The  model presented herein uses modified code from https://khayatrayen.github.io/MCMC.html. I am currently developing a Metropolis-within-Gibbs algorithm for stratigraphic correlation of $\delta$<sup>13</sup>C records with Andrew R. Millard and Martin R. Smith at the [Smith Lab at Durham University](https://smithlabdurham.github.io/#!team).*

In the [previous post](/post/a-metropolis-algorithm-in-r-part-1-implementation), we built a Metropolis algorithm to estimate latitudinal temperature gradients, approximated by a generalised logistic function. Recall that the Metropolis algorithm works by proposing new parameter values and evaluating the joint posterior probability of the model with these values, against the posterior with the current values.

How do we chose a new value for a parameter? A common approach is to sample a normal distribution, centred at the current value (i.e. the mean of the distribution is the current value). Choosing the standard deviation of the proposal distribution ($\sigma_{proposal}$) is more tricky. If $\sigma_{proposal}$ is too high, we end up proposing a lot of values at the far tail ends of the target posterior distribution, which will usually be rejected (see below, green proposals). This leads to inefficient sampling and patchy coverage of the posterior distribution. Conversely, a very small $\sigma_{proposal}$ leads to most new values being accepted, but the resulting Markov chain will move very slowly through the parameter space, leading to a low effective sample size (red proposals below). Instead, some intermediate $\sigma_{proposal}$ is desirable, at which the Markov chain moves quickly through the parameter space, without too many rejections (e.g., yellow proposals below). 

```{r, fig.width = 7, fig.height = 4, warning = FALSE, echo = FALSE}

set.seed(2)
par(mfrow=c(2,1),mar = c(0.5,4,0,0), las = 1)
xd <- seq(-12.2,12.2,0.01)
yd <- dnorm(xd,-1.5,1)+dnorm(xd,1.5,1)
plot(xd,yd, xlab = "", ylab = "density",type = "n", yaxs = "i", xaxs = "i", ylim = c(0,0.43), xaxt = "n", yaxt = "n")
axis(2,seq(0,0.5,0.1), c("0",as.character(seq(0.1,0.4,0.1)),NA))
text(-11.5,0.39,"target distribution", adj = c(0,.5), cex = 1.1)

error_polygon <- function(x,en,ep,color) {
  polygon( c(x[1], x, x[length(x)], x[length(x)], rev(x), x[1]),
           c((ep)[1],ep, (ep)[length(ep)], (en)[length(en)], rev(en), (en)[1]),
           border = NA, col = color)
}
error_polygon(xd,rep(0,length(xd)),yd,rgb(0,0.35,0.7,0.33))
p1 <- -0.75
sd3 <- p1+rnorm(10,0,0.2)
points(sd3,dnorm(sd3,-1.5,1)+dnorm(sd3,1.5,1), pch = 4, cex = 1.2, lwd = 2, col = rgb(0.9,0.3,0,0.75), xpd = T)

sd2 <- p1+rnorm(10,0,2.5)
points(sd2,dnorm(sd2,-1.5,1)+dnorm(sd2,1.5,1), pch = 4, cex = 1.2, lwd = 2, col = rgb(0.8,0.8,0,0.75), xpd = T)

sd1 <- p1+rnorm(10,0,8)
points(sd1,dnorm(sd1,-1.5,1)+dnorm(sd1,1.5,1), pch = 4, cex = 1.2, lwd = 2, col = rgb(0,0.8,0,0.75), xpd = T)

abline(v= -0.75, lty = 3, lwd = 2)
points(-0.75,dnorm(-0.75,-1.5,1)+dnorm(-0.75,1.5,1), pch = 4, cex = 1.75, lwd = 3, col = rgb(0,0,0,0.67), xpd = T)
sigmas <- c(8,2.5,0.2)
legend("topright", as.expression(c("current value",sapply(1:3, function(x) bquote(italic(sigma["proposal"]~"="~.(sigmas[x])))))), 
       col = c(rgb(0,0,0,0.67),rgb(0,0.8,0,0.75),rgb(0.8,0.8,0,0.75),rgb(0.9,0.3,0,0.75)), border = NA, bty = "n", pch = 4, 
       pt.cex = c(1.7,1.2,1.2,1.2), pt.lwd = c(3,2,2,2), cex = 0.95)


par(mar = c(2,4,0.5,0))

plot(xd,yd, xlab = "", ylab = "density (not to scale)",type = "n", yaxs = "i", xaxs = "i", ylim = c(0,0.43), yaxt = "n")
text(-11.5,0.39,"proposal distributions", adj = c(0,.5), cex = 1.1)
axis(2,seq(0,0.5,0.1), c("0",as.character(seq(0.1,0.4,0.1)),NA))


error_polygon(xd,rep(0,length(xd)),dnorm(xd,p1,8)*4,rgb(0,0.8,0,0.275))
error_polygon(xd,rep(0,length(xd)),dnorm(xd,p1,2.5)*1.7,rgb(0.8,0.8,0,0.35))
error_polygon(xd,rep(0,length(xd)),dnorm(xd,p1,0.2)*0.2,rgb(0.9,0.3,0,0.4))


abline(v= -0.75, lty = 3, lwd = 2)
legend("topright", as.expression(sapply(1:3, function(x) bquote(italic(sigma["proposal"]~"="~.(sigmas[x]))))), 
       fill = c(rgb(0,0.8,0,0.275),rgb(0.8,0.8,0,0.35),rgb(0.9,0.3,0,0.4)), border = NA, bty = "n", cex = 0.95)


```

It turns out that, for multidimensional problems, sampling is most efficient if the acceptance rate of proposals is roughly $1/4$ [(Gelman et al. 1997)](https://projecteuclid.org/journals/annals-of-applied-probability/volume-7/issue-1/Weak-convergence-and-optimal-scaling-of-random-walk-Metropolis-algorithms/10.1214/aoap/1034625254.full). 


[source 2](https://www.tandfonline.com/doi/abs/10.1198/jcgs.2009.06134)
